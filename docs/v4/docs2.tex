\PassOptionsToPackage{unicode=true}{hyperref} % options for packages loaded elsewhere
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{biblatex}

\usepackage{unicode-math}
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage[]{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\usepackage{hyperref}
\hypersetup{
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{longtable,booktabs}
% Fix footnotes in tables (requires footnote package)
\IfFileExists{footnote.sty}{\usepackage{footnote}\makesavenoteenv{longtable}}{}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\addbibresource{docs.bib}
% set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother


\date{}

\begin{document}



\hypertarget{gemsec-neuropeptide-docs}{%
\section{GEMSEC Neuropeptide Docs}\label{gemsec-neuropeptide-docs}}

\textbf{January 28, 2019}

\emph{Chris Pecunies, Aaron, Savvy Gupta}

\emph{Led by: Jacob Rodriguez}

\emph{PI: Mehmet Sarikaya}

\hypertarget{abstract}{%
\subsection{Abstract}\label{abstract}}

This documentation covers the phase of the GEMSEC Neuropeptide project involved in the downselection of three candidate peptides through the implementation of several similarity measures in the creation of two similarity matrices, one for each of two known graphene-binding 12-length peptides, principally utilizing Irena Cosic's Resonant Recognition Model.

The purpose of this documentation is to serve as a reference for the motivation, background, methods, and results of the GEMSEC project to discover the method of signal transduction in human neuropeptides, to ultimately discover candidate peptides with binding affinity to graphene, as well as to illuminate their mechanism of binding.

\hypertarget{introduction}{%
\subsection{Introduction}\label{introduction}}

The overarching aim of this project is to uncover the mechanism of signal transduction in neuropeptides which have been experimentally determined by GEMSEC to bind to graphene. To achieve this goal, we will be using several different measures of peptide similarity to ultimately select three peptides from a set of several thousand neuropeptides to experimentally determine the graphene binding of affinity of, ultimately in the overarching goal of determining the relative efficacy of these techniques highly specified peptide synthesis. To determine candidate peptides to be experimented on, we have utilized three principal methods: cross-sequence entropy, PAM30 sequence similarity, and RRM relative to two known binders, \emph{GrBP5} and \emph{M6}

\hypertarget{background}{%
\subsection{Background}\label{background}}

While there is extensive literature surrounding the subject of peptide-solid binding and its most important determinants, we have focused on two primary methods: sequence domain functionality clustering and the \emph{Resonant Recognition Model} proposed by Irena Cosic.

The \emph{Resonant Recognition Model}, or RRM, is a method proposed by Irena Cosic for the analysis of peptides and proteins. The model assumes electron-ion interaction potential (EIIP, hereafter) along the backbone of amino acid chains to be the most significant deteriminant in a peptide or protein's biochemical phenomenological features. For each amino acid, a unique scalar EIIP value can be determined, which allows a amino acid sequence to be converted to a scalar sequence of EIIP values in its most simple form.

\hypertarget{methods}{%
\subsection{Methods}\label{methods}}

\hypertarget{rrm}{%
\paragraph{RRM}\label{rrm}}

The Resonant Recognition Model is a theoretical approach in determining protein functionality, proposed by Irena Cosic. The Resonant Recognition Model (hereafter, RRM) posits that the primary determinant of biological or physiochemical functionlity for a protein or peptide lies in the stochastic delocalized electron potential along its carbon backbone. This premise is motivated by the observed high correlation between the spectra of an amino acid sequence represented numerically according to some unique categorical physical functionality and its biological activity. 

The electron-ion interaction potential is determined by the pseudopotential of delocalized electrons along the backbone of the carbon backbone. In this manner, each of the 20 essential amino acids which form the set of neuropeptides to be analyzed are represented by a scalar EIIP value ranging from 0 (Leucine, Ile) to 0.1263 (Asp). These EIIP values are then used to calculate a spectrum unique to each sequence through a Discrete Fourier Transform (DFT) which is calculated, as proposed by Cosic:

\begin{equation}
    X(n) = \sum x(m) e^{-j\frac{2nm\pi}{N}} \subset n = 1,2 \dots N/2
\end{equation}

These DFT coefficients are ultimately calculated for each neuropeptide sequence. Cosic proposes cross-spectral function between EIIP spectra calculated in this manner, which allows for the determination of shared "characteristic peaks" which, depending on the magnitude and signal-to-noise ratio of the peak, allows for one to theoretically determine how similar one peptide's biochemical and physiochemical functionality is to another. This cross spectrum is calculated as follows:

\begin{equation}
    S(n) = X(n)Y^*(n) \subset n = 1,2 \dots N/2
\end{equation}

This is implemented in our peptide similarity matrix with a manual DFT implementation corresponding to results which cohere to the DFT spectra in the introductory paper and book on the Resonant Recognition Model by Cosic. We initially attempted to implement the DFT using the NumPy and SciPy FFT packages, but struggled to acquire initial results which corresponded to the DFT and cross spectra in the aforementioned paper and book, so the manual implementation was added in with the help of Sid and Aaron.

In the cross spectrum generated by our manual implementation of the DFT outlined by Cosic, the signal-to-noise ratio, calculated by dividing the peak value (whose frequency, should the peak value be distinct enough from its background, corresponds to its \textit{characteristic frequency}) by the mean of all values in the cross spectrum, can be deemed a measure of similarity between the two peptides whose DFT spectra are used to create the cross spectrum. In this manner, we used both the signal-to-noise ratio of the cross spectrum of each neuropeptide to the two known-binding peptides, as well as the correlation coefficient of each neuropeptide's DFT spectrum to the DFT spectrum of the two known-binding peptides as similarity values in the output similarity matrix for each binding peptide.

\hypertarget{domainmatching}{%
\paragraph{Sequence-Function Domain Matching}\label{domainmatching}}

From (where?) we used a mapping of the 20 amino acids to seven different categories, specifically: aromatic structure, hydrophobic function, polar structure, proline (itself), glycine (itself), negative charge, positive charge, and Cystine which is excluded (assigned to a separate category from all others, like proline and glycine). We then implemented a function which returned all possible subsequences of each known-binding peptide, and then for each peptide, returned a list of the longest matching subsequences and their indices for each neuropeptide. This was done for explicit amino acid subsequence matches, as well as for subsequence matches indicated by the seven aforementioned bio-functional categories, which, given the limited domain, corresponded to a less discriminatory pattern-matching algorithm for each neuropeptide. Thus, we implemented two columns, one containing a list of amino acid subsequence matches and one for functional encoding matches (as tuples, paired with their index of coincidence), in our output similarity matrix.

We also implemented a primitive scoring algorithm, which assigned a cumulative score of 1 multiplied by each independent subsequence match added to 1.5 multiplied by the length of each subsequence match, which allowed us to assign a scalar magnitude to the subsequence matches found. It is our intention to optimize the weight tuple (instead of using the arbitrary 1 and 1.5 aforementioned weights) used in this scoring method further in the project, and implement more complex scoring based on the weight of each match's functional mapping, some which may carry more information and explanatory power than others.

\hypertarget{string-distance}{%
\paragraph{String distance}\label{string-distance}}

Although not the primary aim of our project, in the aim of reasonable comprehensiveness we included several algorithm implementations of sequence similarity in the hopes of providing possible insight into the validity of other higher-order derived similarity metrics. The specfic similarity algorithm outputs which we included are as follows: \emph{Jaro-Winkler}, \emph{Needleman-Wunsch}, \emph{Smith-Waterman}, and \emph{Levenshtein}. Each of the aforementioned sequence alignment metrics is unique enough from one another to justify inclusion without potential redundancy in the similarity matrix, and each implements a scoring method that is principally aimed at producing similarity measures for bioinformatic sequences, especially amino acid sequences. Although these are the four measures we included in our final data output for the neuropeptide sequences, the final SequenceSimilarity class provides for many more to be calculated and included in the output .csv file, all included and implemented through the usage of the \emph{textdistance} Python package \cite{omnium_textdistance_2019}

\hypertarget{substitution-matrix-similarity}{%
\paragraph{Substitution Matrix Similarity}\label{substitution-matrix-similarity}}

The PAM (point accepted mutation) matrices, initially developed by Margaret Dayhoff are commonly used in measuring the similarity of two peptide or protein sequences. The PAM30 matrix, specifically, is a sequence alignment matrix that allows 30 point accepted per 100 amino acids. The PAM30 matrix is a ``shallow'' sequence alignment matrix, in that it is more appropriate in determining alignment for more ``similar'' sequences. 

\hypertarget{results}{%
\subsection{Results}\label{results}}

Although we implemented several distinct metrics of similarity in our final two output similarity matrices, the initial and primary motivation for the project laid in exploring Irena Cosic's Resonant Recognition Model as a means for determining peptide behavior, especially with regards to self-assembly, and as such, we weighted the signal-to-noise ratio and correlation coefficient metrics garnered from RRM results the highest, and all other similarity metrics are used at the behest of validating and interpreting the RRM results. The sequence-function-domain pattern matching algorithm represents a relatively novel similarity metric, but its full validity cannot be verified without more experimental effort (or a project on its own).

In implementing the Resonant Recognition Model, we first needed to convert the two known-binding peptides GrBP5 and M6 to its bio-functional encoding (using the mapping listed in the Appendix) as well as its EIIP encoding for DFT spectra calculations, used thereafter for cross-spectral calculations alongside each neuropeptide.

\textbf{\emph{Table 1:}} \emph{Two known-binding peptides under consideration, as well as their bio-functional encoding and scaled EIIP DFT spectrum}

\begin{longtable}[]{@{}lll@{}}
\toprule
\textbf{seq} & numseq & scaled dft\tabularnewline
\midrule
\endhead
IMVTESSDYSSY & 111252250220 & [51.1, 0,  31.2,  21.8, 29.2, 100]\tabularnewline
IMVTASSAYDDY & 111212210550 & [27.3, 84.4, 93.5, 0, 59.1, 100]\tabularnewline
\bottomrule
\end{longtable}

Our ultimate goal in the initial phase of this project is to downselect from the full list of neuropeptides to three candidate peptides, as determined principally through the calculation of cross-spectral signal-to-noise as an alias for peptide similarity. To this end, we used our manual RRM implementation to generate the aforementioned metric (column titled RRM SN in output matrices), and sorted all peptides by their signal-noise ratio with the known-binding peptide of interest, using other metrics as secondary benchmarks to judge candidacy. Below is the similarity matrix for the top five sequences, sorted by signal-to-noise ratio (minus distance values and amino acid encodings):


\textbf{\emph{Table 1:}} \emph{Top 5 sequences by RRM S/N ratio}
\begin{longtable}[]{lllll}
\toprule
\textbf{Sequences}& PAM30 & BLOSUM45 & RRM\_SN & RRM\_Corr  \tabularnewline
\midrule
\endhead
INNDCQNFIGNR & -66   & -10      & 5.46    & 0.69 \\
VPLRPEEDELID & -53   & -3       & 5.42    & 0.65  \\
LNSLDGAGFGFE & -40   & -2       & 5.42    & 0.89  \\
RSFGCRFGTCTV & -66   & -18      & 5.39    & 0.64  \\
SSGGGDGSGMWF & -59   & -14      & 5.27    & 0.78 \\             
\end{longtable}

It was generally observed that RRM cross-spectral signal-to-noise demonstrated low correlation towards most other metrics of similarity (see table 3). Furthermore, in Cosic's introduction to the RRM, a signal-to-noise ratio above 20 was deemed to be notable -- however, given that the signal in her examples (human alpha, beta hemoglobin) were presumed to be many magnitudes higher in length (dealing with proteins, rather than short-length peptides), it is expected that the signal-to-noise ratio would be less meaningful in our signals which are relatively protracted in length (on the order of 10s versus 100s).

\begin{center}
\textbf{\emph{Table 2:}} \emph{Correlation matrix of similarity measures, minus string distance}
\begin{longtable}[]{lllllll}
\toprule
 & PAM30 & BLOSUM45 & RRM\_SN & RRM\_Corr & sseq\_score & num\_score \\
\midrule
\endhead
PAM30 & 1.0 & 0.90 & 0.05 & 0.01 & 0.59 & 0.63 \\
BLOSUM45 & 0.90 & 1.0 & 0.06 & 0.01 & 0.64 & 0.70 \\
RRM\_SN & 0.05 & 0.06 & 1.0 & 0.52 & 0.06 & 0.07 \\
RRM\_Corr & 0.01 & 0.01 & 0.52 & 1.0 & 0.05 & 0.05 \\
sseq\_score & 0.59 & 0.64 & 0.06 & 0.05 & 1.0 & 0.43 \\
num\_score & 0.63 & 0.70 & 0.07 & 0.05 & 0.43 & 1.0
\end{longtable}
\end{center}

However, given that we were most interested in using RRM metrics alongside sequence-domain pattern matching metrics, we decided to observe common sequence motifs among those peptides who had higher cross-spectral signal-to-noise relative to their counterparts, and found that, while some common patterns existed, it was not wholly significant.

\textbf{\emph{Table 3:}} \emph{Top 5 sequences and subsequence matches by RRM S/N ratio}
\begin{longtable}[]{llll}
\toprule
\textbf{Sequences} & RRM\_SN  & sseq\_matches & num\_matches \\ \tabularnewline
\midrule
\endhead
INNDCQNFIGNR  & 5.46   & ('I', 0)      &  ('1', 0), ('22', 5) \\
VPLRPEEDELID  & 5.42    & ('D', 7)      &  ('1', 0), ('1', 2), ('5', 7) \\
LNSLDGAGFGFE & 5.42     &              & ('1', 0), ('5', 4), ('0', 8)           \\
RSFGCRFGTCTV & 5.39    &               & ('2', 10)             \\
SSGGGDGSGMWF & 5.27   &                     & ('0', 11)                       
\end{longtable}



\hypertarget{candidate-peptides}{%
\paragraph{Candidate peptides}\label{candidate-peptides}}

The five similarity metrics generated for each neuropeptide served as a feature set which could be weighted and used to train a regression model, but without experimental data, the relative weights for each feature were chosen by {[}METHOD{]}.

After forwarding the candidate peptides for experimentation, we utilized statistical clustering and signal processing methods to predict determinant sequence domains in graphene binding which could then be used with the experimental data once acquired.

\hypertarget{experimental-results}{%
\paragraph{Experimental results}\label{experimental-results}}

After generating the list of {[}NUMBER{]} candidate peptides and receiving binding affinity metrics, we were then able to perform several statistical methods to ascertain the most influential factors in peptide graphene binding.

First, we trained a simple linear regression model, using the gathered
experimental results as training data, and {[}\ldots{}{]}

\hypertarget{signal-transduction}{%
\paragraph{Signal transduction}\label{signal-transduction}}

From results gathered from model training, statistical clustering, and experimental cross-validation, we were able to identify several sequence patterns and corresponding functions which may prove significant.
{[}\ldots{}{]}

\hypertarget{discussion}{%
\subsection{Discussion}\label{discussion}}

\hypertarget{computational-results}{%
\paragraph{Computational results}\label{computational-results}}

Our program, using all aforementioned computational methods, generated two similarity matrices for 1,612 same-length neuropeptides: one matrix for similarity values relative to GrBP5, and one for the wild-type peptide M6. The






Where the columns correspond as follows:

\begin{itemize}
\tightlist
\item
  \textbf{seq}: Original amino acid sequence of the neuropeptide
\item
  \textbf{numseq}: The original amino acid sequence converted to numbers
  corresponding to their biological function as determined by the
  biological function key-value table{[}\^{}6{]}
\item
  \textbf{rrmsn}: The signal-to-noise ratio of the cross-signal of the
  EIIP frequency spectum calculated for a given neuropeptide and the
  sequence of comparison, normalized in the domain {[}0, 100{]}.
\item
  \textbf{rrmcor}: The Pearson correlation coefficient between the EIIP
  frequency spectrum calculated for a given neuropeptide and the
  sequence of comparison, mapped to the domain {[}0, 100{]}
\item
  \textbf{pam30}: The PAM30 similarity score (formula described in
  methods section); a measure of inverse distance using the PAM30
  matrix, mapped to {[}0, 100{]}
\item
  \textbf{numentr}: The cross-entropy of the numerical sequence
  represencted by \texttt{numseq}
\item
  \textbf{aaentr}: The cross-entropy of the amino acid sequence
\end{itemize}

From this data, we determined that {[}\ldots{}{]}

\hypertarget{experimental-results-1}{%
\paragraph{Experimental results}\label{experimental-results-1}}

{[}to be completed after experimentaiton{]}

\hypertarget{clustering-and-signal-analysis}{%
\paragraph{Clustering and signal
analysis}\label{clustering-and-signal-analysis}}

After gathering the experimental results, we were then able to apply
supervised statistical learning techniques to the full set of
neuropeptides, as well as signal processing techniques. We first
{[}\ldots{}{]}

\hypertarget{how-to-run}{%
\subsection{How to run}\label{how-to-run}}

\textbf{Prerequisites}: A computer running Windows/Mac OSX/Linux with
\href{https://www.python.org/}{Python} (3+) installed, and the Python
libraries \href{https://pandas.pydata.org/}{pandas},
\href{https://numpy.org/}{NumPy}, and
\href{https://scikit-learn.org/stable/}{scikit-learn}. For
visualizations, the library \href{https://matplotlib.org/}{matplotlib}
should be installed. If these libraries are not already installed,
instructions for their installation will be listed below.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Download the \href{http://google.com}{.zip containing all .py files
  and sample data set} \textbf{{[}!FIX{]}} and extract to preferred
  location.
\item
  Open a terminal and navigate to the directory containing the extracted
  files

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \item
    On Windows, press the Windows key and type ``cmd'', and the press
    enter. \texttt{dir} lists all files and folders in the working
    directory, while \texttt{cd\ dirName} changes the working directory
    to the specified folder (in this case, \texttt{dirname}). To move up
    the directory hierarchy, type \texttt{cd\ ../}
  \item
    On Mac OSX, enter spotlight search with Command + Spacebar and type
    ``Terminal'', then hit enter. Instructions are the same as for
    windows, but replace \texttt{dir} with \texttt{ls}.
  \item
    On Linux, a terminal is likely easily accessible. Commands are the
    same as for Mac OSX.
  \end{enumerate}
\item
  When in the directory containing the extracted files, type the
  following command to generate the ``similarity tables'' for the
  example dataset: \texttt{python\ main.py\ example\_data.csv}

  \begin{itemize}
  \item
    This can be run with any .csv sequence file, but it must follow the
    same schema as the example\_data.csv table provided, and the
    sequences must all be of the same length relative to each other as
    well as to the known binder(s) (non length-matching input sequences
    will be ignored in output)
  \item
    \emph{(To implement)} The script accepts as a second argument a
    sequence (or list of sequences), each of which will generate its own
    similarity table for the input .csv.

    \begin{itemize}
    \item
      If no argument is given (as above), it will generate two .csv
      similarity tables, one for GrBP5 and one for M6. To specify only
      one .csv output similarity table (for GrBP5), run
      \texttt{python\ main.py\ example\_data.csv\ grbp5}.
    \item
      This can be done for an arbitrary number of different sequences,
      for example:
      \texttt{python\ main.py\ example\_data.csv\ IVTSSY\ UVGEASTT\ EEVTUSGMII}
      will output three .csv tables for peptides in
      \texttt{example\_data.csv} of lengths corresponding to each
      sequence specified by the user.
    \item
      Finally, the second argument can itself be a .csv of sequences,
      following the same schema as the first input .csv. In this way,
      for a .csv entered as a second argument with 10 rows of sequences
      will generate 10 separate .csv tables.
    \end{itemize}
  \end{itemize}
\item
  Similarity tables and visualizations will be generated in a folder
  titled ``output'' located in the same directory as the
  \texttt{main.py} file.
\end{enumerate}

\hypertarget{appendix}{%
\subsection{Appendix}\label{appendix}}

\hypertarget{table-1-aa}{%
\paragraph{Table 1: AA}\label{table-1-aa}}

\begin{longtable}[]{@{}llll@{}}
\toprule
Function & AA & Num & EIIP\tabularnewline
\midrule
\endhead
Aromatic & F & 0 & 0.0946\tabularnewline
Aromatic & Y & 0 & 0.0516\tabularnewline
Aromatic & W & 0 & 0.0548\tabularnewline
Hydrophobic & A & 1 & 0.0373\tabularnewline
Hydrophobic & V & 1 & 0.0057\tabularnewline
Hydrophobic & I & 1 & O.0000\tabularnewline
Hydrophobic & L & 1 & 0.0000\tabularnewline
Hydrophobic & M & 1 & 0.0823\tabularnewline
Polar & S & 2 & 0.0829\tabularnewline
Polar & T & 2 & 0.0941\tabularnewline
Polar & N & 2 & 0.0036\tabularnewline
Polar & Q & 2 & 0.0761\tabularnewline
Proline & P & 3 & 0.0198\tabularnewline
Glycine & G & 4 & 0.0050\tabularnewline
Charge (-) & D & 5 & 0.1263\tabularnewline
Charge (-) & E & 5 & 0.0058\tabularnewline
Charge (+) & K & 6 & 0.0371\tabularnewline
Charge (+) & H & 6 & 0.0242\tabularnewline
Charge (+) & R & 6 & 0.0959\tabularnewline
Excluded & C & 7 & 0.0829\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{bibliography}{%
\subsection{Bibliography}\label{bibliography}}



\end{document}



{[}1\^{}{]} https://www.ncbi.nlm.nih.gov/pubmed/7851912 (EIIP
representation)

{[}2\^{}{]} https://www.aclweb.org/anthology/J06-4002.pdf (kendall tau,
nlp, similarity?)

{[}3\^{}{]}
https://nonlinearbiomedphys.biomedcentral.com/articles/10.1186/1753-4631-1-7
