{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport pandas as pd\\nfrom scipy.spatial.distance import euclidean, pdist, squareform\\n\\n\\ndef similarity_func(u, v):\\n    return 1/(1+euclidean(u,v))\\n\\nDF_var = pd.DataFrame.from_dict({\"s1\":[1.2,3.4,10.2],\"s2\":[1.4,3.1,10.7],\"s3\":[2.1,3.7,11.3],\"s4\":[1.5,3.2,10.9]})\\nDF_var.index = [\"g1\",\"g2\",\"g3\"]\\n\\ndists = pdist(DF_var, similarity_func)\\nDF_euclid = pd.DataFrame(squareform(dists), columns=DF_var.index, index=DF_var.index)\\n'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Class to calculate several simialrity metrics for an input list of peptides given a sequence string to compare it to.\n",
    "USAGE: \n",
    "1. Create SequenceSimilarityObject({sequence string}, {dictionary of data paths} (to be deprecated soon -- use\n",
    "   internal class data), {path to peptides csv}, {column title of sequence values of aforementioned peptides csv})\n",
    "   for any number of sequences you want to be compared to the list of peptides\n",
    "2. For each object, call object.generate_similarity() to fill out the Dataframe with similarity metrics\n",
    "3. To whittle down this similarity matrix to list only those peptides with pattern matching of a minimum length\n",
    "   at a matching index in the rerence peptide (henceforth the binder), call object.get_df_with_binder_subseqs(min_length={#})\n",
    "@ Author: Chris Pecunies, with help from Savvy Gupta and Aaron Tsang\n",
    "@ Date: February 12, 2020\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Set, Tuple, Dict, List\n",
    "from scipy import interpolate, stats, fftpack, signal\n",
    "#import sci-kit learn\n",
    "import textdistance as td\n",
    "#import biopython as bio\n",
    "\n",
    "class SequenceSimilarity:\n",
    "    '''\n",
    "    Class that takes in a path to a list of amino acid sequences as well\n",
    "    as any number of peptide sequences explicitly that are known to have\n",
    "    a certain set of properties. Generates metrics for similarity for each\n",
    "    peptide in path and returns domains AA sequence with high similarity\n",
    "    '''\n",
    "    AA = list('FYWAVILMSTNQPGDEKHRC')\n",
    "    \n",
    "    def __init__(self, binder: Tuple[str, str],\n",
    "                 data: SeqData,\n",
    "                 p_path: str,       \n",
    "                 aa_col: str,\n",
    "                 min_length: int = 0,\n",
    "                 dists: List = [],\n",
    "                 only_match: bool = False):       \n",
    "        \n",
    "        # ---- setting data ---------\n",
    "        \n",
    "        #self.conv = [\"NUM\", \"EIIP\", \"FNS\"]\n",
    "        self.d = {d: vars(data)[d] for d in list(vars(data).keys())}\n",
    "        self.conv = list(sl['conv'].keys())\n",
    "        self.aa_col = [aa_col]\n",
    "        self.sim_cols = ['PAM30', 'BLOSUM', 'RRM_SN', 'RRM_Corr', 'weighted_matches']\n",
    "        self.match_cols = ['sseq_matches', ]\n",
    "        self.conv_cols = [conv+'_Seq' for conv in self.conv]\n",
    "        self.cols = self.aa_col + self.sim_cols + self.conv_cols + self.match_cols\n",
    "        self.AA_map = {cnv:dict(zip(self.AA, self.d['conv'][cnv])) for cnv in self.conv}\n",
    "        self.bname, self.b = binder\n",
    "        # finds all possible subsequences and locations in binder in tuple (sseq, ind)\n",
    "        self.bsseq = [(self.b[i:j], i) for i, _ in enumerate(self.b) for j in range(i+1, len(self.b)+1)]\n",
    "        \n",
    "        # ---- helper lambda functions\n",
    "        self.AA_conv = lambda typ, p: tuple(self.AA_map[typ][AA] if AA in self.AA else 0 for AA in p)\n",
    "        self.sim_sum = lambda p1, p2, t: sum([self.d['matr'][t][a1][a2] for a1 in p1 for a2 in p2])\n",
    "        \n",
    "        self.p_og = pd.read_csv(p_path)\n",
    "        self.__set_peps(aa_col, min_length, only_match)\n",
    "        self.__update_similarities(dists)\n",
    "        \n",
    "        \n",
    "        \n",
    "    #----------------SET UP FUNCTIONS (void)-------------------------------#\n",
    "    \n",
    "    def __set_peps(self, aa_col:str, minlen: int = 0, matchonly: bool = False):\n",
    "        self.p_og = self.p_og.drop_duplicates()\n",
    "        self.p_og = self.p_og[~self.p_og[aa_col].str.contains(\"O\")]\n",
    "        self.p = self.p_og[self.p_og[aa_col].str.len() == len(self.b)]\n",
    "        if not list(self.p):  raise Exception(\"No peptides of same length as binder found\")\n",
    "        self.pdata = pd.DataFrame(index=self.p.index, columns=self.cols)\n",
    "        self.pdata_match = pd.concat([self.df_filter_subseq(ss,i) for (ss,i) in self.bsseq if len(ss) >= minlen])\n",
    "        self.p_match = self.pdata_match[aa_col]\n",
    "        if matchonly: self.p, self.pdata = self.pmatch, self.pdata_match\n",
    "\n",
    "            \n",
    "    def _update_AA_conversion(self) -> None:\n",
    "        \"\"\"if seq.signaltonoise(cross) < max(sn):\n",
    "        Adds to the initially empty column values for conv_type (possible choices\n",
    "        'EIIP' and 'Num' for now) the conversion of the AA sequence in the self.aa_col\n",
    "        column a list representing its conversion\n",
    "        \"\"\"\n",
    "        for conv in enumerate(self.conv):\n",
    "            if conv == 'NUM':\n",
    "                self.pdata[conv+\"_Seq\"] = [str([str(n) for n in self.AA_conv(conv, p)]) for p in self.p]\n",
    "            else:\n",
    "                self.pdata[conv+\"_Seq\"] = [self.AA_conv(conv, p) for p in self.p]\n",
    "    \n",
    "    def _update_matrix_similarity(self) -> None:\n",
    "        \"\"\"\n",
    "        Just updates the similarity columns for the output similarity dataframe.\n",
    "        Uses lambda helper function self.sim_sum in __init__\n",
    "        \"\"\"\n",
    "        for m in list(self.d['matr'].keys()):\n",
    "            sim = [self.sim_sum(p, self.b, m) for p in self.p]\n",
    "            self.pdata[m] = np.interp(sim, (min(sim), max(sim)), (0,1))\n",
    "        \n",
    "\n",
    "    def _update_RRM_similarity(self) -> None:\n",
    "        \"\"\"\n",
    "        Uses the Resonant Recognition Model as described by Irena Cosic to \n",
    "        \"\"\"\n",
    "        \n",
    "        bnd_eiip = self.AA_conv('EIIP', self.b)\n",
    "        bnd_dft = get_dft_from_eiip(bnd_eiip)\n",
    "        sn = []\n",
    "        do = []\n",
    "        best_sn = None\n",
    "        best_dot = None\n",
    "        \n",
    "        def signaltonoise(a, axis=0, ddof=0):\n",
    "            a = np.asanyarray(a)\n",
    "            m = a.mean(axis)\n",
    "            sd = a.std(axis=axis, ddof=ddof)\n",
    "            return np.where(sd == 0, 0, m/sd)\n",
    "        \n",
    "        for pep in self.p:\n",
    "            seq_eiip =self.AA_conv('EIIP', pep)\n",
    "            seq_dft = np.fft.rfft(seq_eiip)\n",
    "            \n",
    "            cross = signal.correlation(seq_dft, bnd_dft)\n",
    "            dot = np.dot(seq_dft, bnd_dft)\n",
    "            SN = np.mean(np.real(signaltonoise(cross, axis=None)))\n",
    "            do.append(dot)\n",
    "            sn.append(SN)\n",
    "            if not sn and SN >= max(sn):\n",
    "                best_sn = (pep, seq_dft)\n",
    "            if not do or dot >= max(do):\n",
    "                best_dot = (pep, seq_dft)\n",
    "            \n",
    "        sn_out = np.interp(sn, (min(sn), max(sn)), (0,1))\n",
    "        dot_out = np.interp(do, (min(do), max(do)), (0,1))\n",
    "        self.pdata['RRM_Corr'] = dot_out\n",
    "        self.pdata['RRM_SN'] = sn_out\n",
    "        \n",
    "    def get_spectrums() -> pd.DataFrame:\n",
    "        pass\n",
    "    \n",
    "    # NOTE! Adds columns \"Matching_sseqs\" and \"Num_matching\" to output\n",
    "    # Might be too unwieldy / unhelpful for output similarity data\n",
    "    # if so, just comment out _update_matching_sseqs()\n",
    "    def _update_matching_sseqs(self, single_match_weight: float = 1, weight: float = 1) -> None:\n",
    "        \"\"\"\n",
    "        Returns a number as a new column representing the number of \"matches\" a peptide\n",
    "        has for all possible subsequences for the binder inputted at a given index. For\n",
    "        weighting=1, all matches are treated equally ('Y' at position 3 is treated equal\n",
    "        to IMV at position 0) but lowering weighting lowers smaller-length matches\n",
    "        \"\"\"\n",
    "        # @TODO Remove \"duplicates\" which occur at different matching indexes of binder\n",
    "        # but are part of a larger pattern already recorded at an earlier index\n",
    "        self.pdata['sseq_matches'] = None\n",
    "        self.pdata['weighted_matches'] = None\n",
    "        \n",
    "        score: float = lambda s: (single_match_weight * 1) + (len(s)**weight)\n",
    "        matches: List = list(); nmatches = list()\n",
    "        for i, seq in enumerate(self.p):\n",
    "            matches.append(list()); nmatches.append(int())\n",
    "            for j, AA in enumerate(seq): \n",
    "                lmatch: Tuple = None\n",
    "                for k, (sseq, bin_i) in enumerate(self.bsseq):\n",
    "                    in_seq = seq[j:len(sseq)+j]\n",
    "                    if (bin_i == j) and (in_seq == sseq): \n",
    "                        if lmatch is not None:\n",
    "                            if seq[lmatch[0]:lmatch[0]+lmatch[1]].find(in_seq) >= 0:\n",
    "                                continue\n",
    "                        if self.bsseq[k-1][1] == bin_i:\n",
    "                            nmatches[i] -= score(matches[i].pop()[0])\n",
    "                            lmatch = (bin_i, len(sseq))\n",
    "                        matches[i].append((sseq, bin_i))\n",
    "                        nmatches[i] += score(sseq)\n",
    "        \n",
    "        self.pdata['sseq_matches'] = matches\n",
    "        self.pdata['weighted_matches'] = np.interp(nmatches, (min(nmatches), max(nmatches)), (0,1))\n",
    "        self.sim_cols += ['weighted_matches']\n",
    "        self.cols += ['sseq_matches', 'weighted_matches']\n",
    "        \n",
    "                    \n",
    "    def _remove_matching_sseqs_column(self) -> None:\n",
    "        \"\"\"\n",
    "        Just removes the binder sseq pattern matches list column and number\n",
    "        of matching (with/without) weighting if they exist\n",
    "        \"\"\"\n",
    "        if self.pdata.columns.contains(self.match_cols):\n",
    "            self.cols.remove(self.match_cols)\n",
    "            self.pdata = self.pdata.drop(columns=self.match_cols)\n",
    "            \n",
    "    def _update_distances(self, metrics: List = []) -> None:\n",
    "        \"\"\"\n",
    "        Adds Hamming, Levenstein, etc. distance metrics for sequences in peptide list\n",
    "        Metrics can be specified by name string in parameter\n",
    "        \"\"\"\n",
    "        dists = metrics if metrics else list(self.d['dist'].keys())\n",
    "        dist_vals = [[d['dist'][d](p, self.b) for p in self.p] for d in dists]\n",
    "        self.pdata[dists] = dist_vals\n",
    "        self.cols += dists\n",
    "        self.sim_cols += dists\n",
    "                \n",
    "                \n",
    "    def update_similarities(self, metrics: List = []) -> None:\n",
    "        '''\n",
    "        Updates the similarity values whenever called (for now should be only once right\n",
    "        after creating the object, ecept possibly if the Binding peptide is updated\n",
    "        (should be handled automatically)\n",
    "        '''\n",
    "        self._update_AA_conversion()\n",
    "        self._update_matrix_similarity()\n",
    "        self._update_RRM_similarity()\n",
    "        self._update_matching_sseqs()\n",
    "        if metrics is not None: \n",
    "            self._update_distances(metrics) if metrics else self._update_distances()\n",
    "        # OPTIONAL\n",
    "        # self._unpack_num_encoding()\n",
    "        \n",
    "    #----------MAIN CLASS FUNCTIONS (returns data) ------------------------#\n",
    "\n",
    "    def df_filter_subseq(self, sub_seq: str, ind: int = None) -> pd.DataFrame:\n",
    "        '''\n",
    "        Takes in a subsequence of equal or lesser length to\n",
    "        peptides in class peptide dataframe and returns a dataframe\n",
    "        containing only those peptides containing the sequence\n",
    "        '''\n",
    "        if not {*sub_seq}.issubset({*self.AA}):\n",
    "            raise Exception('Invalid subsequence')\n",
    "        if ind is None:\n",
    "            return self.pdata[self.p.str.contains(sub_seq)]\n",
    "        return self.pdata[self.p.str.find(sub_seq) == ind]\n",
    "\n",
    "    def sim_sum_matrix(self, seq) -> pd.DataFrame:\n",
    "        return self.data.filter\n",
    "        \n",
    "    \n",
    "    def merge_data(self, other, sep_cols = False) -> pd.DataFrame:\n",
    "        # !!! IMPORTANT: \"other\" must also be SequenceSimilarity object (couldnt compile)\n",
    "        \"\"\"\n",
    "        Returns a merged Dataframe of self.pdata and another SequenceSimilarity's pep_data.\n",
    "        If sep_cols=True, then the other SequenceSimilarity's columns will simply be appended\n",
    "        to the returned DataFrame (self.pdata is unchanged). If False, results will be averaged.\n",
    "        @NOTE: This is a super naive implementatoin -- expand this to make it more configurable\n",
    "        @TODO: Take in *others as a list of arbitrarily many other SequenceSimilarities to compare\n",
    "        \"\"\"\n",
    "        # must be same length binders -> so same peptides of interest\n",
    "        this_data = self.pdata.copy()\n",
    "        non_seq_cols = self.sim_cols.copy()\n",
    "        seq_cols = self.aa_col + self.conv_cols\n",
    "        other_data = other.pep_data.copy()\n",
    "        if sep_cols:\n",
    "            if len(list(this_data.cols)) == len(list(other_data.cols)):\n",
    "                d = this_data.merge(right=other_data, on=self.aa_col, suffixes=(\"_\"+self.bname, \"_\"+other.bname))\n",
    "                return d.drop_duplicates()\n",
    "            else:\n",
    "                raise Exception(\"Mismatched columns\")\n",
    "\n",
    "        new_cols = ['{}_{}_{}'.format(col, self.bname, other.bname) for col in self.sim_cols]\n",
    "        out_data = pd.DataFrame(index=this_data.index, columns=seq_cols + new_cols)\n",
    "        out_data[seq_cols] = this_data[seq_cols]\n",
    "        both = pd.concat([this_data[non_seq_cols],other_data[non_seq_cols]])\n",
    "        out_data[new_cols] = both.groupby(both.index).mean()\n",
    "        if 'sseq_matches' in self.cols or 'sseq_matches' in other.cols:\n",
    "            both_match = self.pdata['sseq_matches'].append(other.pdata['sseq_matches'])\n",
    "            both['sseq_matches'] = both_match\n",
    "            out_data.join(both_match)\n",
    "        return out_data\n",
    "                    \n",
    "        #@TODO Finish\n",
    "                \n",
    "                \n",
    "    #-------------------miscellaneous methods------------------------------#\n",
    "    \n",
    "#     def get_kendalltau_corr_map(self) -> Tuple:\n",
    "#         return stats.kendalltau(self.data['AA_MAP'][['Num']], self.data['AA_MAP'][['EIIP']])\n",
    "    \n",
    "class SeqData:\n",
    "\n",
    "    CONV = {\n",
    "        'NUM': [0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 4, 5, 5, 6, 6, 6, 7],\n",
    "        'EIIP' : [0.0946, 0.0516, 0.0548, 0.0373, 0.0057, 0.0, 0.0, 0.0823,\\\n",
    "                 0.0829, 0.0941, 0.0036, 0.0761, 0.0198, 0.005, 0.1263, 0.0058, \\\n",
    "                 0.0371, 0.0242, 0.0959, 0.0829],\n",
    "        'FNS' : ['Aromatic', 'Aromatic', 'Aromatic', 'Hydrophobic', 'Hydrophobic', \\\n",
    "                'Hydrophobic', 'Hydrophobic', 'Hydrophobic', 'Polar', 'Polar', 'Polar', \\\n",
    "                'Polar', 'Proline', 'Glycine', 'Charge (-)', 'Charge (-)', 'Charge (+)', \\\n",
    "                'Charge (+)', 'Charge (+)', 'Excluded'],\n",
    "    }\n",
    "    # @TODO: Import Biopython dicts of matrices, not read from .csvs\n",
    "    MATR = {\n",
    "        'PAM30': pd.read_csv('./src_data/pam30.csv', index_col=0).to_dict(),\n",
    "        'BLOSUM45': pd.read_csv('./src_data/BLOSUM.csv', index_col=0).to_dict(),\n",
    "    }\n",
    "    DIST = {\n",
    "        'jaro_winkler': (lambda p1, p2: td.jaro_winkler.normalized_similarity(p1, p2)),\n",
    "        'needleman_wunsch': (lambda p1, p2: td.needleman_wunsch.normalized_similarity(p1, p2)),\n",
    "        'smith_waterman': (lambda p1, p2: td.smith_waterman.normalized_similarity(p1, p2)),\n",
    "        'levenshtein': (lambda p1, p2: td.levenshtein.normalized_similarity(p1, p2))\n",
    "    }\n",
    "    \n",
    "    def __init__(self, conv=CONV.keys(), matr=MATR.keys(), dist=DIST.keys()):\n",
    "        \n",
    "        self.conv = {cnv:self.CONV[cnv] for cnv in self.CONV.keys() if cnv in conv}\n",
    "        self.matr = {mtr:self.MATR[mtr] for mtr in self.MATR.keys() if mtr in matr}\n",
    "        self.dist = {dst:self.DIST[dst] for dst in self.DIST.keys() if dst in dist}\n",
    "    \n",
    "'''\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import euclidean, pdist, squareform\n",
    "\n",
    "\n",
    "def similarity_func(u, v):\n",
    "    return 1/(1+euclidean(u,v))\n",
    "\n",
    "DF_var = pd.DataFrame.from_dict({\"s1\":[1.2,3.4,10.2],\"s2\":[1.4,3.1,10.7],\"s3\":[2.1,3.7,11.3],\"s4\":[1.5,3.2,10.9]})\n",
    "DF_var.index = [\"g1\",\"g2\",\"g3\"]\n",
    "\n",
    "dists = pdist(DF_var, similarity_func)\n",
    "DF_euclid = pd.DataFrame(squareform(dists), columns=DF_var.index, index=DF_var.index)\n",
    "'''\n",
    "\n",
    "# @TODO Dynamically filter peptide set based on length(s) of input sequences of binders\n",
    "#       i.e. 2 binders, one 11 AA long, one 13 AA long, each gets their own \"subset\" of the\n",
    "#       full peptide lilst that can be compared to it. For any number of input sequences\n",
    "\n",
    "# @TODO implement method for both similarities to M6 and GrBP5 to interrelate and act as their own feature set:\n",
    "# i.e. if a peptide matches both peptides in temrs of sequence at some index, that should be important rather than\n",
    "# having it equal to one matching only one\n",
    "\n",
    "# @TODO: Maybe as originally planned implement binders inputted as dictionary of multiple values, each with separate\n",
    "#      dataframes within the same class --> for big similarity calculations. Or just create multiple SequenceSimilarity instances\n",
    "# @TODO: Implement method to apply relevant similarity scoring algorithms (distance metrics, ex) for\n",
    "#       non-same-length peptides. Could even be stored alongside same length peptides\n",
    "# @TODO Simplify some of the df filtering going on with Dataframe.where() or Dataframe.mask or Dataframe.query or isin\n",
    "# @TODO Implement some patterns as being DEFINING features of binders -- ie. endi with letter 1 letter 2 letter 2 letter 1 or starting with IMVT always"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>=' not supported between instances of 'int' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-5aa9677899e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mPEP_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./src_data/Sequence_data.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m dat1 = {\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;34m'grbp5_sim'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mSequenceSimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEQS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPEP_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAA_COL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;34m'm6_sim'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mSequenceSimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEQS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPEP_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAA_COL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;34m'grbp5_sim_match'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mSequenceSimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEQS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPEP_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAA_COL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-71-0bdd6aadc014>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, binder, data, p_path, aa_col, min_length, dists, only_match)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp_og\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__set_peps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maa_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monly_match\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__update_similarities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-71-0bdd6aadc014>\u001b[0m in \u001b[0;36m__set_peps\u001b[0;34m(self, aa_col, minlen, matchonly)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No peptides of same length as binder found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdata_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf_filter_subseq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbsseq\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mminlen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdata_match\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maa_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmatchonly\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpmatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdata_match\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-71-0bdd6aadc014>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No peptides of same length as binder found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdata_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf_filter_subseq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbsseq\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mminlen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdata_match\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maa_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmatchonly\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpmatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdata_match\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '>=' not supported between instances of 'int' and 'list'"
     ]
    }
   ],
   "source": [
    "# Consider using Organized NPS from Savvy's folder?\n",
    "# def __init__(self, binder: Tuple[str, str],\n",
    "#                  data: SeqData,\n",
    "#                  p_path: str,       \n",
    "#                  aa_col: str,\n",
    "#                  min_length: int = 0,\n",
    "#                  dists: List = [],\n",
    "#                  only_match: bool = False):    \n",
    "DATA = SeqData()\n",
    "SEQS = [\n",
    "    ('GRBP5','IMVTESSDYSSY'),\n",
    "    ('M6','IMVTASSAYDDY')\n",
    "]\n",
    "AA_COL = 'Sequences'\n",
    "PEP_PATH = './src_data/Sequence_data.csv' \n",
    "dat1 = {\n",
    "    'grbp5_sim' : SequenceSimilarity(SEQS[0], DATA, PEP_PATH, AA_COL, [], False),\n",
    "    'm6_sim' : SequenceSimilarity(SEQS[1], DATA, PEP_PATH, AA_COL, [], False),\n",
    "    'grbp5_sim_match' : SequenceSimilarity(SEQS[0], DATA, PEP_PATH, AA_COL, [], True),\n",
    "    'm6_sim_match' : SequenceSimilarity(SEQS[1], DATA, PEP_PATH, AA_COL, [], True),\n",
    "}\n",
    "dat2 = {\n",
    "    'both_sep_sim' : dat1['grbp5_sim'].merge_data(other=dat1['m6_sim'], sep_cols=True),\n",
    "    'both_avg_sim' : dat1['grbp5_sim'].merge_data(other=dat1['m6_sim'], sep_cols=False),\n",
    "    'both_sep_sim_match' : dat1['grbp5_sim_match'].merge_data(other=dat1['m6_sim_match'], sep_cols=True),\n",
    "    'both_avg_sim_match' : dat1['grbp5_sim_match'].merge_data(other=dat1['m6_sim_match'], sep_cols=False),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>=' not supported between instances of 'int' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-5aa9677899e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mPEP_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./src_data/Sequence_data.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m dat1 = {\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;34m'grbp5_sim'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mSequenceSimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEQS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPEP_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAA_COL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;34m'm6_sim'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mSequenceSimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEQS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPEP_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAA_COL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;34m'grbp5_sim_match'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mSequenceSimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEQS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPEP_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAA_COL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-64-fe781ad34faa>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, binder, data, p_path, aa_col, min_length, dists, only_match)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp_og\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__set_peps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maa_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monly_match\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__update_similarities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-64-fe781ad34faa>\u001b[0m in \u001b[0;36m__set_peps\u001b[0;34m(self, aa_col, minlen, matchonly)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No peptides of same length as binder found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdata_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf_filter_subseq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbsseq\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mminlen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdata_match\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maa_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmatchonly\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpmatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdata_match\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-64-fe781ad34faa>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No peptides of same length as binder found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdata_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf_filter_subseq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbsseq\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mminlen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdata_match\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maa_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmatchonly\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpmatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdata_match\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '>=' not supported between instances of 'int' and 'list'"
     ]
    }
   ],
   "source": [
    "# Consider using Organized NPS from Savvy's folder?\n",
    "# def __init__(self, binder: Tuple[str, str],\n",
    "#                  data: SeqData,\n",
    "#                  p_path: str,       \n",
    "#                  aa_col: str,\n",
    "#                  min_length: int = 0,\n",
    "#                  dists: List = [],\n",
    "#                  only_match: bool = False):    \n",
    "DATA = SeqData()\n",
    "SEQS = [\n",
    "    ('GRBP5','IMVTESSDYSSY'),\n",
    "    ('M6','IMVTASSAYDDY')\n",
    "]\n",
    "AA_COL = 'Sequences'\n",
    "PEP_PATH = './src_data/Sequence_data.csv' \n",
    "dat1 = {\n",
    "    'grbp5_sim' : SequenceSimilarity(SEQS[0], DATA, PEP_PATH, AA_COL, [], False),\n",
    "    'm6_sim' : SequenceSimilarity(SEQS[1], DATA, PEP_PATH, AA_COL, [], False),\n",
    "    'grbp5_sim_match' : SequenceSimilarity(SEQS[0], DATA, PEP_PATH, AA_COL, [], True),\n",
    "    'm6_sim_match' : SequenceSimilarity(SEQS[1], DATA, PEP_PATH, AA_COL, [], True),\n",
    "}\n",
    "dat2 = {\n",
    "    'both_sep_sim' : dat1['grbp5_sim'].merge_data(other=dat1['m6_sim'], sep_cols=True),\n",
    "    'both_avg_sim' : dat1['grbp5_sim'].merge_data(other=dat1['m6_sim'], sep_cols=False),\n",
    "    'both_sep_sim_match' : dat1['grbp5_sim_match'].merge_data(other=dat1['m6_sim_match'], sep_cols=True),\n",
    "    'both_avg_sim_match' : dat1['grbp5_sim_match'].merge_data(other=dat1['m6_sim_match'], sep_cols=False),\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
